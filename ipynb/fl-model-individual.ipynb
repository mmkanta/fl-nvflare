{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9124d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import classification_report,confusion_matrix,multilabel_confusion_matrix\n",
    "import transformers\n",
    "from PIL import Image\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import os\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8339f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmar.custom.pylon.trainer.start import *\n",
    "from mmar.custom.pylon.utils.pretrain import *\n",
    "from mmar.custom.pylon.model.common import *\n",
    "from mmar.custom.pylon.pylon import PylonConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca1f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import HorizontalFlip, Rotate, RandomBrightnessContrast, Flip, Compose, RandomResizedCrop\n",
    "from typing import List, Optional, Dict, Generator, NamedTuple, Any, Tuple, Union, Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a32aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "labels_col = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Pneumothorax', 'Edema']\n",
    "classes = 5 # number of findings\n",
    "image_w = 256\n",
    "image_h = 256\n",
    "batch_size = 32\n",
    "n_labels = len(labels_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e6c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "def dicom2array(path, voi_lut=True, fix_monochrome=True):\n",
    "    \"\"\"Convert DICOM file to numy array\n",
    "    \n",
    "    Args: \n",
    "        path (str): Path to the DICOM file to be converted\n",
    "        voi_lut (bool): Whether or not VOI LUT is available\n",
    "        fix_monochrome (bool): Whether or not to apply MONOCHROME fix\n",
    "        \n",
    "    Returns:\n",
    "        Numpy array of the respective DICOM file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the pydicom library to read the DICOM file\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "        \n",
    "    # Depending on this value, X-ray may look inverted - fix that\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    # Normalize the image array\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27443b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, target_transform=None):\n",
    "      self.img_files = df['Image'].tolist()\n",
    "      self.img_labels = df[labels_col].values\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "      self.image_dir = image_dir\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      img_path = os.path.join(self.image_dir, self.img_files[idx])\n",
    "      if '.dcm' in self.img_files[idx]:\n",
    "        image = dicom2array(img_path)\n",
    "        image = torch.tensor(image)/255\n",
    "        image = image.unsqueeze(0)\n",
    "      else:\n",
    "        image = read_image(img_path, mode=ImageReadMode.GRAY)/255\n",
    "\n",
    "      label = self.img_labels[idx]\n",
    "      if self.transform:\n",
    "          image = image[0].numpy()\n",
    "          aug = self.transform(image=image)\n",
    "          image = torch.from_numpy(aug[\"image\"])\n",
    "          image = image.unsqueeze(0)\n",
    "      image = image.unsqueeze(0)\n",
    "      image = F.interpolate(image, size=image_w)\n",
    "      image = image[0]\n",
    "      # image = image.expand(3, -1, -1)\n",
    "      return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9599cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb675e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(p=0.5):\n",
    "    return Compose([\n",
    "        RandomResizedCrop(image_h,image_w,scale=(0.7, 1.0), p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomBrightnessContrast(0.5,0.5,p=0.5),\n",
    "        Rotate(90, border_mode=0, p=0.5),\n",
    "    ], p=p)\n",
    "augmentation = augment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3842382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'nih' # edit\n",
    "sites = ['chula', 'nih', 'padchest', 'mimic']\n",
    "col_list = ['Image', 'Atelectasis', 'Cardiomegaly', 'Edema', 'Effusion', 'Pneumothorax']\n",
    "labels_col = col_list[1:]\n",
    "\n",
    "data_path = '/workspace/nvflare/fl-nvflare/data/'\n",
    "site_path = data_path + 'data_' + site_name\n",
    "IMAGE_PATH = site_path + '/image'\n",
    "\n",
    "# train and val from 1 site\n",
    "train = pd.read_csv(site_path + '/train_' + site_name + '.csv')\n",
    "val = pd.read_csv(site_path + '/val_' + site_name + '.csv')\n",
    "# test = pd.read_csv(site_path + '/test_' + site_name + '.csv')\n",
    "\n",
    "# test from all sites\n",
    "# test = pd.DataFrame(columns=col_list)\n",
    "# for s in sites:   \n",
    "#     df = pd.read_csv(data_path + s + '/test_' + s + '.csv')\n",
    "#     df['Image'] = df['Image'].apply(lambda x: data_path + s + '/image/' + x)\n",
    "#     test = pd.concat([test,df],axis=0)\n",
    "# test = test.sample(frac=1).reset_index(drop=True)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b470e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = XRayDataset(train, IMAGE_PATH, transform=augmentation)\n",
    "valid_dataset = XRayDataset(val, IMAGE_PATH)\n",
    "# test_dataset = XRayDataset(test, IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a834fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39beb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        net_conf = PylonConfig(\n",
    "            n_in=1,\n",
    "            n_out=n_labels,\n",
    "            up_type='2layer',\n",
    "            pretrain_conf=PretrainConfig(\n",
    "                pretrain_name='nih',\n",
    "                path='/workspace/nvflare/fl-nvflare/pylon,nih,256.pkl',\n",
    "            ),\n",
    "            freeze='enc',\n",
    "        )\n",
    "        self.image_model = net_conf.make_model()\n",
    "    \n",
    "    def forward(self,image):\n",
    "        image_output = self.image_model(image)\n",
    "        return image_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25844f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: _IncompatibleKeys(missing_keys=['net.segmentation_head.0.weight', 'net.segmentation_head.0.bias'], unexpected_keys=[])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (image_model): Pylon(\n",
       "    (net): PylonCore(\n",
       "      (encoder): ResNetEncoder(\n",
       "        (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder): PylonDecoder(\n",
       "        (pa): PA(\n",
       "          (mid): Sequential(\n",
       "            (0): ConvBnRelu(\n",
       "              (conv): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (down1): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(2048, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "              (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (down2): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "              (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (down3): Sequential(\n",
       "            (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (conv3): ConvBnRelu(\n",
       "            (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBnRelu(\n",
       "            (conv): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): ConvBnRelu(\n",
       "            (conv): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (up3): UP(\n",
       "          (conv1): Sequential(\n",
       "            (0): ConvBnRelu(\n",
       "              (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (up2): UP(\n",
       "          (conv1): Sequential(\n",
       "            (0): ConvBnRelu(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (up1): UP(\n",
       "          (conv1): Sequential(\n",
       "            (0): ConvBnRelu(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnRelu(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (segmentation_head): SegmentationHead(\n",
       "        (0): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Identity()\n",
       "        (2): Activation(\n",
       "          (activation): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pool): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a07d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd38fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d74c1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "[Train] Step [50/156], Loss: 2.3804, time: 43.2931s\n",
      "[Train] Step [100/156], Loss: 1.3912, time: 40.3766s\n",
      "[Train] Step [150/156], Loss: 1.0129, time: 39.9900s\n",
      "[Train] Epoch 0/49, Loss: 2.1514\n",
      "Save model_best, Loss: 0.9272\n",
      "[Eval] Epoch 0/49, Loss: 0.9272\n",
      "----------\n",
      "Epoch 1/49\n",
      "[Train] Step [50/156], Loss: 0.6640, time: 39.2003s\n",
      "[Train] Step [100/156], Loss: 0.4884, time: 39.2703s\n",
      "[Train] Step [150/156], Loss: 0.3798, time: 40.1508s\n",
      "[Train] Epoch 1/49, Loss: 0.6075\n",
      "Save model_best, Loss: 0.3970\n",
      "[Eval] Epoch 1/49, Loss: 0.3970\n",
      "----------\n",
      "Epoch 2/49\n",
      "[Train] Step [50/156], Loss: 0.3306, time: 39.4084s\n",
      "[Train] Step [100/156], Loss: 0.2552, time: 40.3635s\n",
      "[Train] Step [150/156], Loss: 0.3610, time: 39.5869s\n",
      "[Train] Epoch 2/49, Loss: 0.3312\n",
      "Save model_best, Loss: 0.2724\n",
      "[Eval] Epoch 2/49, Loss: 0.2724\n",
      "----------\n",
      "Epoch 3/49\n",
      "[Train] Step [50/156], Loss: 0.2695, time: 39.7408s\n",
      "[Train] Step [100/156], Loss: 0.2416, time: 39.3476s\n",
      "[Train] Step [150/156], Loss: 0.1993, time: 40.8159s\n",
      "[Train] Epoch 3/49, Loss: 0.2515\n",
      "Save model_best, Loss: 0.2224\n",
      "[Eval] Epoch 3/49, Loss: 0.2224\n",
      "----------\n",
      "Epoch 4/49\n",
      "[Train] Step [50/156], Loss: 0.2383, time: 40.6383s\n",
      "[Train] Step [100/156], Loss: 0.2229, time: 39.1953s\n",
      "[Train] Step [150/156], Loss: 0.1824, time: 39.5250s\n",
      "[Train] Epoch 4/49, Loss: 0.2217\n",
      "Save model_best, Loss: 0.2047\n",
      "[Eval] Epoch 4/49, Loss: 0.2047\n",
      "----------\n",
      "Epoch 5/49\n",
      "[Train] Step [50/156], Loss: 0.1749, time: 39.1005s\n",
      "[Train] Step [100/156], Loss: 0.1703, time: 39.0376s\n",
      "[Train] Step [150/156], Loss: 0.1740, time: 39.3279s\n",
      "[Train] Epoch 5/49, Loss: 0.2057\n",
      "Save model_best, Loss: 0.1919\n",
      "[Eval] Epoch 5/49, Loss: 0.1919\n",
      "----------\n",
      "Epoch 6/49\n",
      "[Train] Step [50/156], Loss: 0.2067, time: 41.4214s\n",
      "[Train] Step [100/156], Loss: 0.1693, time: 39.7379s\n",
      "[Train] Step [150/156], Loss: 0.1514, time: 40.1082s\n",
      "[Train] Epoch 6/49, Loss: 0.1949\n",
      "Save model_best, Loss: 0.1865\n",
      "[Eval] Epoch 6/49, Loss: 0.1865\n",
      "----------\n",
      "Epoch 7/49\n",
      "[Train] Step [50/156], Loss: 0.1594, time: 40.2468s\n",
      "[Train] Step [100/156], Loss: 0.1271, time: 40.4159s\n",
      "[Train] Step [150/156], Loss: 0.2106, time: 38.7827s\n",
      "[Train] Epoch 7/49, Loss: 0.1874\n",
      "Save model_best, Loss: 0.1803\n",
      "[Eval] Epoch 7/49, Loss: 0.1803\n",
      "----------\n",
      "Epoch 8/49\n",
      "[Train] Step [50/156], Loss: 0.2056, time: 39.1366s\n",
      "[Train] Step [100/156], Loss: 0.2227, time: 39.1561s\n",
      "[Train] Step [150/156], Loss: 0.1513, time: 39.8768s\n",
      "[Train] Epoch 8/49, Loss: 0.1819\n",
      "Save model_best, Loss: 0.1765\n",
      "[Eval] Epoch 8/49, Loss: 0.1765\n",
      "----------\n",
      "Epoch 9/49\n",
      "[Train] Step [50/156], Loss: 0.1457, time: 40.7630s\n",
      "[Train] Step [100/156], Loss: 0.1429, time: 39.6982s\n",
      "[Train] Step [150/156], Loss: 0.2091, time: 40.2197s\n",
      "[Train] Epoch 9/49, Loss: 0.1781\n",
      "Save model_best, Loss: 0.1730\n",
      "[Eval] Epoch 9/49, Loss: 0.1730\n",
      "----------\n",
      "Epoch 10/49\n",
      "[Train] Step [50/156], Loss: 0.2063, time: 39.6904s\n",
      "[Train] Step [100/156], Loss: 0.2014, time: 39.6980s\n",
      "[Train] Step [150/156], Loss: 0.1812, time: 39.3432s\n",
      "[Train] Epoch 10/49, Loss: 0.1744\n",
      "Save model_best, Loss: 0.1710\n",
      "[Eval] Epoch 10/49, Loss: 0.1710\n",
      "----------\n",
      "Epoch 11/49\n",
      "[Train] Step [50/156], Loss: 0.0984, time: 39.4975s\n",
      "[Train] Step [100/156], Loss: 0.1314, time: 39.4275s\n",
      "[Train] Step [150/156], Loss: 0.1880, time: 40.9039s\n",
      "[Train] Epoch 11/49, Loss: 0.1735\n",
      "Save model_best, Loss: 0.1684\n",
      "[Eval] Epoch 11/49, Loss: 0.1684\n",
      "----------\n",
      "Epoch 12/49\n",
      "[Train] Step [50/156], Loss: 0.1226, time: 40.0223s\n",
      "[Train] Step [100/156], Loss: 0.1329, time: 38.8492s\n",
      "[Train] Step [150/156], Loss: 0.1373, time: 41.6165s\n",
      "[Train] Epoch 12/49, Loss: 0.1688\n",
      "Save model_best, Loss: 0.1674\n",
      "[Eval] Epoch 12/49, Loss: 0.1674\n",
      "----------\n",
      "Epoch 13/49\n",
      "[Train] Step [50/156], Loss: 0.1013, time: 40.5464s\n",
      "[Train] Step [100/156], Loss: 0.1733, time: 39.7728s\n",
      "[Train] Step [150/156], Loss: 0.2112, time: 39.3230s\n",
      "[Train] Epoch 13/49, Loss: 0.1687\n",
      "Save model_best, Loss: 0.1672\n",
      "[Eval] Epoch 13/49, Loss: 0.1672\n",
      "----------\n",
      "Epoch 14/49\n",
      "[Train] Step [50/156], Loss: 0.1121, time: 39.2684s\n",
      "[Train] Step [100/156], Loss: 0.2388, time: 39.9012s\n",
      "[Train] Step [150/156], Loss: 0.1964, time: 39.6689s\n",
      "[Train] Epoch 14/49, Loss: 0.1672\n",
      "Save model_best, Loss: 0.1647\n",
      "[Eval] Epoch 14/49, Loss: 0.1647\n",
      "----------\n",
      "Epoch 15/49\n",
      "[Train] Step [50/156], Loss: 0.1404, time: 40.9073s\n",
      "[Train] Step [100/156], Loss: 0.1782, time: 39.4057s\n",
      "[Train] Step [150/156], Loss: 0.1199, time: 39.7377s\n",
      "[Train] Epoch 15/49, Loss: 0.1662\n",
      "Save model_best, Loss: 0.1631\n",
      "[Eval] Epoch 15/49, Loss: 0.1631\n",
      "----------\n",
      "Epoch 16/49\n",
      "[Train] Step [50/156], Loss: 0.1036, time: 39.9746s\n",
      "[Train] Step [100/156], Loss: 0.1750, time: 43.0091s\n",
      "[Train] Step [150/156], Loss: 0.2113, time: 39.9070s\n",
      "[Train] Epoch 16/49, Loss: 0.1618\n",
      "Save model_best, Loss: 0.1631\n",
      "[Eval] Epoch 16/49, Loss: 0.1631\n",
      "----------\n",
      "Epoch 17/49\n",
      "[Train] Step [50/156], Loss: 0.1671, time: 41.5063s\n",
      "[Train] Step [100/156], Loss: 0.1052, time: 41.2977s\n",
      "[Train] Step [150/156], Loss: 0.2603, time: 40.6967s\n",
      "[Train] Epoch 17/49, Loss: 0.1615\n",
      "Save model_best, Loss: 0.1623\n",
      "[Eval] Epoch 17/49, Loss: 0.1623\n",
      "----------\n",
      "Epoch 18/49\n",
      "[Train] Step [50/156], Loss: 0.1687, time: 40.1975s\n",
      "[Train] Step [100/156], Loss: 0.1636, time: 39.6476s\n",
      "[Train] Step [150/156], Loss: 0.1481, time: 40.6585s\n",
      "[Train] Epoch 18/49, Loss: 0.1597\n",
      "Save model_best, Loss: 0.1611\n",
      "[Eval] Epoch 18/49, Loss: 0.1611\n",
      "----------\n",
      "Epoch 19/49\n",
      "[Train] Step [50/156], Loss: 0.1250, time: 39.4046s\n",
      "[Train] Step [100/156], Loss: 0.1812, time: 40.6895s\n",
      "[Train] Step [150/156], Loss: 0.1940, time: 38.9044s\n",
      "[Train] Epoch 19/49, Loss: 0.1582\n",
      "Save model_best, Loss: 0.1603\n",
      "[Eval] Epoch 19/49, Loss: 0.1603\n",
      "----------\n",
      "Epoch 20/49\n",
      "[Train] Step [50/156], Loss: 0.1733, time: 39.6388s\n",
      "[Train] Step [100/156], Loss: 0.1618, time: 38.7764s\n",
      "[Train] Step [150/156], Loss: 0.1828, time: 39.7714s\n",
      "[Train] Epoch 20/49, Loss: 0.1564\n",
      "INFO: Early stopping counter 1 of 10\n",
      "[Eval] Epoch 20/49, Loss: 0.1613\n",
      "----------\n",
      "Epoch 21/49\n",
      "[Train] Step [50/156], Loss: 0.1649, time: 39.2656s\n",
      "[Train] Step [100/156], Loss: 0.1514, time: 38.4555s\n",
      "[Train] Step [150/156], Loss: 0.2916, time: 40.8053s\n",
      "[Train] Epoch 21/49, Loss: 0.1549\n",
      "INFO: Early stopping counter 2 of 10\n",
      "[Eval] Epoch 21/49, Loss: 0.1607\n",
      "----------\n",
      "Epoch 22/49\n",
      "[Train] Step [50/156], Loss: 0.0928, time: 39.7110s\n",
      "[Train] Step [100/156], Loss: 0.1349, time: 39.7065s\n",
      "[Train] Step [150/156], Loss: 0.1267, time: 39.5621s\n",
      "[Train] Epoch 22/49, Loss: 0.1552\n",
      "INFO: Early stopping counter 3 of 10\n",
      "[Eval] Epoch 22/49, Loss: 0.1605\n",
      "----------\n",
      "Epoch 23/49\n",
      "[Train] Step [50/156], Loss: 0.1318, time: 39.5579s\n",
      "[Train] Step [100/156], Loss: 0.1565, time: 39.7488s\n",
      "[Train] Step [150/156], Loss: 0.1533, time: 38.3545s\n",
      "[Train] Epoch 23/49, Loss: 0.1535\n",
      "INFO: Early stopping counter 4 of 10\n",
      "[Eval] Epoch 23/49, Loss: 0.1605\n",
      "----------\n",
      "Epoch 24/49\n",
      "[Train] Step [50/156], Loss: 0.1954, time: 39.5881s\n",
      "[Train] Step [100/156], Loss: 0.1942, time: 39.2358s\n",
      "[Train] Step [150/156], Loss: 0.1170, time: 39.7189s\n",
      "[Train] Epoch 24/49, Loss: 0.1525\n",
      "Save model_best, Loss: 0.1592\n",
      "[Eval] Epoch 24/49, Loss: 0.1592\n",
      "----------\n",
      "Epoch 25/49\n",
      "[Train] Step [50/156], Loss: 0.1186, time: 39.8866s\n",
      "[Train] Step [100/156], Loss: 0.0964, time: 40.5064s\n",
      "[Train] Step [150/156], Loss: 0.1694, time: 38.7983s\n",
      "[Train] Epoch 25/49, Loss: 0.1517\n",
      "Save model_best, Loss: 0.1589\n",
      "[Eval] Epoch 25/49, Loss: 0.1589\n",
      "----------\n",
      "Epoch 26/49\n",
      "[Train] Step [50/156], Loss: 0.1780, time: 39.7166s\n",
      "[Train] Step [100/156], Loss: 0.1143, time: 40.9817s\n",
      "[Train] Step [150/156], Loss: 0.1781, time: 39.4626s\n",
      "[Train] Epoch 26/49, Loss: 0.1496\n",
      "Save model_best, Loss: 0.1582\n",
      "[Eval] Epoch 26/49, Loss: 0.1582\n",
      "----------\n",
      "Epoch 27/49\n",
      "[Train] Step [50/156], Loss: 0.1323, time: 39.1564s\n",
      "[Train] Step [100/156], Loss: 0.1391, time: 38.7490s\n",
      "[Train] Step [150/156], Loss: 0.0895, time: 39.7391s\n",
      "[Train] Epoch 27/49, Loss: 0.1478\n",
      "INFO: Early stopping counter 1 of 10\n",
      "[Eval] Epoch 27/49, Loss: 0.1584\n",
      "----------\n",
      "Epoch 28/49\n",
      "[Train] Step [50/156], Loss: 0.1641, time: 39.1043s\n",
      "[Train] Step [100/156], Loss: 0.1837, time: 38.9923s\n",
      "[Train] Step [150/156], Loss: 0.1480, time: 39.6355s\n",
      "[Train] Epoch 28/49, Loss: 0.1475\n",
      "INFO: Early stopping counter 2 of 10\n",
      "[Eval] Epoch 28/49, Loss: 0.1601\n",
      "----------\n",
      "Epoch 29/49\n",
      "[Train] Step [50/156], Loss: 0.1447, time: 39.9629s\n",
      "[Train] Step [100/156], Loss: 0.1264, time: 39.2428s\n",
      "[Train] Step [150/156], Loss: 0.1130, time: 38.9925s\n",
      "[Train] Epoch 29/49, Loss: 0.1456\n",
      "INFO: Early stopping counter 3 of 10\n",
      "[Eval] Epoch 29/49, Loss: 0.1596\n",
      "----------\n",
      "Epoch 30/49\n",
      "[Train] Step [50/156], Loss: 0.1396, time: 39.5517s\n",
      "[Train] Step [100/156], Loss: 0.1834, time: 39.0268s\n",
      "[Train] Step [150/156], Loss: 0.1080, time: 38.6648s\n",
      "[Train] Epoch 30/49, Loss: 0.1425\n",
      "INFO: Early stopping counter 4 of 10\n",
      "[Eval] Epoch 30/49, Loss: 0.1596\n",
      "----------\n",
      "Epoch 31/49\n",
      "[Train] Step [50/156], Loss: 0.2296, time: 39.3533s\n",
      "[Train] Step [100/156], Loss: 0.2044, time: 39.5600s\n",
      "[Train] Step [150/156], Loss: 0.1471, time: 39.0802s\n",
      "[Train] Epoch 31/49, Loss: 0.1422\n",
      "INFO: Early stopping counter 5 of 10\n",
      "[Eval] Epoch 31/49, Loss: 0.1589\n",
      "----------\n",
      "Epoch 32/49\n",
      "[Train] Step [50/156], Loss: 0.1737, time: 38.7845s\n",
      "[Train] Step [100/156], Loss: 0.1242, time: 40.3501s\n",
      "[Train] Step [150/156], Loss: 0.2358, time: 39.9911s\n",
      "[Train] Epoch 32/49, Loss: 0.1441\n",
      "INFO: Early stopping counter 6 of 10\n",
      "[Eval] Epoch 32/49, Loss: 0.1594\n",
      "----------\n",
      "Epoch 33/49\n",
      "[Train] Step [50/156], Loss: 0.1440, time: 39.6923s\n",
      "[Train] Step [100/156], Loss: 0.0819, time: 40.0663s\n",
      "[Train] Step [150/156], Loss: 0.1356, time: 38.8381s\n",
      "[Train] Epoch 33/49, Loss: 0.1426\n",
      "INFO: Early stopping counter 7 of 10\n",
      "[Eval] Epoch 33/49, Loss: 0.1591\n",
      "----------\n",
      "Epoch 34/49\n",
      "[Train] Step [50/156], Loss: 0.1319, time: 39.6796s\n",
      "[Train] Step [100/156], Loss: 0.1037, time: 39.4424s\n",
      "[Train] Step [150/156], Loss: 0.0776, time: 40.6285s\n",
      "[Train] Epoch 34/49, Loss: 0.1380\n",
      "INFO: Early stopping counter 8 of 10\n",
      "[Eval] Epoch 34/49, Loss: 0.1592\n",
      "----------\n",
      "Epoch 35/49\n",
      "[Train] Step [50/156], Loss: 0.1783, time: 39.5658s\n",
      "[Train] Step [100/156], Loss: 0.0998, time: 39.9287s\n",
      "[Train] Step [150/156], Loss: 0.1520, time: 40.5660s\n",
      "[Train] Epoch 35/49, Loss: 0.1375\n",
      "INFO: Early stopping counter 9 of 10\n",
      "[Eval] Epoch 35/49, Loss: 0.1600\n",
      "----------\n",
      "Epoch 36/49\n",
      "[Train] Step [50/156], Loss: 0.1460, time: 38.9855s\n",
      "[Train] Step [100/156], Loss: 0.1098, time: 39.4494s\n",
      "[Train] Step [150/156], Loss: 0.1205, time: 39.4551s\n",
      "[Train] Epoch 36/49, Loss: 0.1358\n",
      "INFO: Early stopping counter 10 of 10\n",
      "INFO: Early stopping\n",
      "Early stopping at val_loss : 0.1593769889762144\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "val_loss_arr = []\n",
    "min_loss = 10\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "end_epoch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f'Epoch {epoch}/{epochs-1}')\n",
    "\n",
    "  # train\n",
    "  running_loss = 0.0\n",
    "  s = time.time()\n",
    "  n_total_steps = len(train_dataloader)\n",
    "  model.train()\n",
    "  for i, (images, labels) in enumerate(train_dataloader):  \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(True):\n",
    "      outputs = model(images)\n",
    "      outputs = outputs.pred\n",
    "      # print(outputs)\n",
    "      loss = criterion(outputs, labels.float())\n",
    "  \n",
    "      # Backward and optimize\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item() * images.size(0)\n",
    "      if (i+1) % 50 == 0:\n",
    "          print (f'[Train] Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, time: {(time.time()-s):.4f}s')\n",
    "          s = time.time()\n",
    "  epoch_loss = running_loss / len(train_dataset)\n",
    "  loss_arr.append(epoch_loss)\n",
    "  print (f'[Train] Epoch {epoch}/{epochs-1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "  # eval\n",
    "  running_loss = 0.0\n",
    "  s = time.time()\n",
    "  n_total_steps = len(valid_dataloader)\n",
    "  model.eval()\n",
    "  for i, (images, labels) in enumerate(valid_dataloader):  \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    with torch.set_grad_enabled(False):\n",
    "      outputs = model(images)\n",
    "      outputs = outputs.pred\n",
    "      loss = criterion(outputs, labels.float())\n",
    "      running_loss += loss.item() * images.size(0)\n",
    "  \n",
    "  epoch_loss = running_loss / len(valid_dataset)\n",
    "  val_loss_arr.append(epoch_loss)\n",
    "  # save model with min loss\n",
    "  if min_loss > epoch_loss:\n",
    "    min_loss = epoch_loss\n",
    "    torch.save(model.state_dict(), site_path + '/model_best_nih.pth') \n",
    "    print(f'Save model_best, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "  early_stopping(epoch_loss)\n",
    "  if early_stopping.early_stop:\n",
    "    print(f\"Early stopping at val_loss : {epoch_loss}\")\n",
    "    end_epoch = epoch\n",
    "    break\n",
    "\n",
    "  print (f'[Eval] Epoch {epoch}/{epochs-1}, Loss: {epoch_loss:.4f}')\n",
    "  print('-' * 10)\n",
    "  end_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1369f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(end_epoch+1), loss_arr, label='Training Loss')\n",
    "plt.plot(range(end_epoch+1), val_loss_arr, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('nih_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971a52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
